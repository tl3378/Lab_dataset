Title,Link,Authors,Publish Date,Topic,Author 1 Name,Author 1 H-index,Author 2 Name,Author 2 H-index,Abstract
"Towards Fair RAG: On the Impact of Fair Ranking in Retrieval-Augmented
 Generation",https://arxiv.org/pdf/2409.11598,"To Eun Kim, Fernando Diaz",2024-09-17T23:10:04Z,RAG,To Eun Kim,4, Fernando Diaz,51,"Abstract Many language models now enhance their responses with retrieval capabilities, leading to the widespread adoption of retrieval-augmented generation (RAG) systems. However, despite retrieval being a core component of RAG, much of the research in this area overlooks the extensive body of work on fair ranking, neglecting the importance of considering all stakeholders involved. This paper presents the first systematic evaluation of RAG systems integrated with fair rankings. We focus specifically on measuring the fair exposure of each relevant item across the rankings utilized by RAG systems (i.e., item-side fairness), aiming to promote equitable growth for relevant item providers. To gain a deep understanding of the relationship between item-fairness, ranking quality, and generation quality in the context of RAG, we analyze nine different RAG systems that incorporate fair rankings across seven distinct datasets. Our findings indicate that RAG systems with fair rankings can maintain a high level of generation quality and, in many cases, even outperform traditional RAG systems, despite the general trend of a tradeoff between ensuring fairness and maintaining system-effectiveness. We believe our insights lay the groundwork for responsible and equitable RAG systems and open new avenues for future research. We publicly release our codebase and dataset."
"Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey
 on How to Make your LLMs use External Data More Wisely",https://arxiv.org/pdf/2409.14924,"Siyun Zhao, Yuqing Yang, Zilong Wang, Zhiyuan He, Luna K. Qiu, Lili Qiu",2024-09-23T11:20:20Z,"Retrieval Augmented Generation, RAG",Siyun Zhao,N/A,Yuqing Yang,16,"Large language models (LLMs) augmented with external data have demonstrated remarkable capabilities in completing real-world tasks. External data not only bolsters the models_ domain-specific expertise and temporal relevance but also diminishes incidences of hallucination, thereby enhancing both the controllability and interpretability of outputs. Techniques for integrating external data into LLMs, such as Retrieval-Augmented Generation (RAG) and fine-tuning, are gaining increasing attention and widespread application. Nonetheless, the effective deployment of data-augmented LLMs across various specialized fields presents substantial challenges. These challenges encompass a wide range of issues, from retrieving relevant data and accurately interpreting user intent to fully harnessing the reasoning capabilities of LLMs for complex tasks. We believe that there is no one-size-fits-all solution for data-augmented LLM applications. In practice, underperformance often arises from a failure to correctly identify the core focus of a task or because the task inherently requires a blend of multiple capabilities that must be disentangled for better resolution. In this survey, we propose a RAG task categorization method, classifying user queries into four levels based on the type of external data required and the task__ primary focus: explicit fact queries, implicit fact queries, interpretable rationale queries, and hidden rationale queries. We define these levels of queries, provide relevant datasets, and summarize the key challenges and most effective techniques for addressing these challenges. Finally, we discuss three main forms of integrating external data into LLMs: context, small model, and fine-tuning, highlighting their respective strengths, limitations, and the types of problems they are suited to solve. This work aims to help readers thoroughly understand and decompose the data requirements and key bottlenecks in building LLM applications, offering solutions to the different challenges and serving as a guide to systematically developing such applications."
"GenAI-powered Multi-Agent Paradigm for Smart Urban Mobility:
 Opportunities and Challenges for Integrating Large Language Models (LLMs) and
 Retrieval-Augmented Generation (RAG) with Intelligent Transportation Systems",https://arxiv.org/pdf/2409.00494,"Haowen Xu, Jinghui Yuan, Anye Zhou, Guanhao Xu, Wan Li, Xuegang Ban, Xinyue Ye",2024-08-31T16:14:42Z,RAG,Haowen Xu,7,Jinghui Yuan,32,"Leveraging recent advances in generative AI, multi-agent systems are increasingly being developed to enhance the functionality and efficiency of smart city applications. This paper explores the transformative potential of large language models (LLMs) and emerging Retrieval-Augmented Generation (RAG) technologies in Intelligent Transportation Systems (ITS), paving the way for innovative solutions to address critical challenges in urban mobility. We begin by providing a comprehensive overview of the current state-of-the-art in mobility data, ITS, and Connected Vehicles (CV) applications. Building on this review, we discuss the rationale behind RAG and examine the opportunities for integrating these Generative AI (GenAI) technologies into the smart mobility sector. We propose a conceptual framework aimed at developing multi-agent systems capable of intelligently and conversationally delivering smart mobility services to urban commuters, transportation operators, and decision-makers. Our approach seeks to foster an autonomous and intelligent approach that (a) promotes science-based advisory to reduce traffic congestion, accidents, and carbon emissions at multiple scales, (b) facilitates public education and engagement in participatory mobility management, and (c) automates specialized transportation management tasks and the development of critical ITS platforms, such as data analytics and interpretation, knowledge representation, and traffic simulations. By integrating LLM and RAG, our approach seeks to overcome the limitations of traditional rule-based multi-agent systems, which rely on fixed knowledge bases and limited reasoning capabilities. This integration paves the way for a more scalable, intuitive, and automated multi-agent paradigm, driving advancements in ITS and urban mobility."
"A RAG Approach for Generating Competency Questions in Ontology
 Engineering",https://arxiv.org/pdf/2409.08820,"Xueli Pan, Jacco van Ossenbruggen, Victor de Boer, Zhisheng Huang",2024-09-13T13:34:32Z,"RAG, Ontology",Xueli Pan,3,Jacco van Ossenbruggen,38,"Competency question (CQ) formulation is central to several ontology development and evaluation methodologies. Traditionally, the task of crafting these competency questions heavily relies on the effort of domain experts and knowledge engineers which is often timeconsuming and labor-intensive. With the emergence of Large Language Models (LLMs), there arises the possibility to automate and enhance this process. Unlike other similar works which use existing ontologies or knowledge graphs as input to LLMs, we present a retrieval-augmented generation (RAG) approach that uses LLMs for the automatic generation of CQs given a set of scientific papers considered to be a domain knowledge base. We investigate its performance and specifically, we study the impact of different number of papers to the RAG and different temperature setting of the LLM. We conduct experiments using GPT-4 on two domain ontology engineering tasks and compare results against groundtruth CQs constructed by domain experts. Empirical assessments on the results, utilizing evaluation metrics (precision and consistency), reveal that compared to zero-shot prompting, adding relevant domain knowledge to the RAG improves the performance of LLMs on generating CQs for concrete ontology engineering tasks."
"LA-RAG:Enhancing LLM-based ASR Accuracy with Retrieval-Augmented
 Generation",https://arxiv.org/pdf/2409.08597,"Shaojun Li, Hengchao Shang, Daimeng Wei, Jiaxin Guo, Zongyao Li, Xianghui He, Min Zhang, Hao Yang",2024-09-13T07:28:47Z,RAG,Shaojun Li,5,Hengchao Shang,9,"Recent advancements in integrating speech information into large language models (LLMs) have significantly improved automatic speech recognition (ASR) accuracy. However, existing methods often constrained by the capabilities of the speech encoders under varied acoustic conditions, such as accents. To address this, we propose LA-RAG, a novel RetrievalAugmented Generation (RAG) paradigm for LLM-based ASR. LA-RAG leverages fine-grained token-level speech datastores and a speech-to-speech retrieval mechanism to enhance ASR accuracy via LLM in-context learning (ICL) capabilities. Experiments on Mandarin and various Chinese dialect datasets demonstrate significant improvements in ASR accuracy compared to existing methods, validating the effectiveness of our approach, especially in handling accent variations. Index Terms__arge language model, retrieval-augmented generation, speech retrieval, speech recognition, in-context learning."
Trustworthiness in Retrieval-Augmented Generation Systems: A Survey,https://arxiv.org/pdf/2409.10102,"Yujia Zhou, Yan Liu, Xiaoxi Li, Jiajie Jin, Hongjin Qian, Zheng Liu, Chaozhuo Li, Zhicheng Dou, Tsung-Yi Ho, Philip S. Yu",2024-09-16T09:06:44Z,Other,Yujia Zhou,12,Yan Liu,97,"Retrieval-Augmented Generation (RAG) has quickly grown into a pivotal paradigm in the development of Large Language Models (LLMs). While much of the current research in this field focuses on performance optimization, particularly in terms of accuracy and efficiency, the trustworthiness of RAG systems remains an area still under exploration. From a positive perspective, RAG systems are promising to enhance LLMs by providing them with useful and up-to-date knowledge from vast external databases, thereby mitigating the long-standing problem of hallucination. While from a negative perspective, RAG systems are at the risk of generating undesirable contents if the retrieved information is either inappropriate or poorly utilized. To address these concerns, we propose a unified framework that assesses the trustworthiness of RAG systems across six key dimensions: factuality, robustness, fairness, transparency, accountability, and privacy. Within this framework, we thoroughly review the existing literature on each dimension. Additionally, we create the evaluation benchmark regarding the six dimensions and conduct comprehensive evaluations for a variety of proprietary and opensource models. Finally, we identify the potential challenges for future research based on our investigation results. Through this work, we aim to lay a structured foundation for future investigations and provide practical insights for enhancing the trustworthiness of RAG systems in real-world applications."
MoRAG -- Multi-Fusion Retrieval Augmented Generation for Human Motion,https://arxiv.org/pdf/2409.12140,"Kalakonda Sai Shashank, Shubh Maheshwari, Ravi Kiran Sarvadevabhatla",2024-09-18T17:03:30Z,"Retrieval Augmented Generation, RAG",Kalakonda Sai Shashank,2,Shubh Maheshwari,4,"We introduce MoRAG, a novel multi-part fusion based retrieval-augmented generation strategy for text-based human motion generation. The method enhances motion diffusion models by leveraging additional knowledge obtained through an improved motion retrieval process. By effectively prompting large language models (LLMs), we address spelling errors and rephrasing issues in motion retrieval. Our approach utilizes a multi-part retrieval strategy to improve the generalizability of motion retrieval across the language space. We create diverse samples through the spatial composition of the retrieved motions. Furthermore, by utilizing low-level, part-specific motion information, we can construct motion samples for unseen text descriptions. Our experiments demonstrate that our framework can serve as a plug-and-play module, improving the performance of motion diffusion models. Code, pretrained models and sample videos will be made available at: https://motionrag.github.io/"
"Familiarity-aware Evidence Compression for Retrieval Augmented
 Generation",https://arxiv.org/pdf/2409.12468,"Dongwon Jung, Qin Liu, Tenghao Huang, Ben Zhou, Muhao Chen",2024-09-19T05:14:55Z,Other,Dongwon Jung,1,Qin Liu,35,"Retrieval Augmented Generation (RAG) improves large language models (LMs) by incorporating non-parametric knowledge through evidence retrieval from external sources. However, it often struggles to filter out inconsistent and irrelevant information that can distract the LM from its tasks. While compressing the retrieved evidence with a compression model aims to address this issue, the compressed evidence may still be unfamiliar to the target model used for downstream task, potentially failing to utilize the evidence effectively. We propose FAVICOMP (Familiarity-aware Evidence Compression), a novel training-free evidence compression technique that makes retrieved evidence more familiar to the target model, while seamlessly integrating parametric knowledge from the model. Specifically, FAVICOMP proactively lowers the perplexity of the compressed evidence with regard to the target model by combining token probabilities from both the compression model and the target model to generate context that is more familiar to the target model. This approach balances the integration of parametric and non-parametric knowledge, which is especially helpful in complex tasks where the retrieved evidence set may not contain all the necessary information. Experimental results demonstrate that FAVICOMP consistently outperforms existing baselines in multiple open-domain QA datasets, achieving high compression rates and showcasing the effective integration of both parametric and non-parametric knowledge."
GEM-RAG: Graphical Eigen Memories For Retrieval Augmented Generation,https://arxiv.org/pdf/2409.15566,"Brendan Hogan Rappazzo, Yingheng Wang, Aaron Ferber, Carla Gomes",2024-09-23T21:42:47Z,"Retrieval Augmented Generation, RAG",Brendan Hogan Rappazzo,12,Yingheng Wang,8,"The ability to form, retrieve, and reason about memories in response to stimuli serves as the cornerstone for general intelligence - shaping entities capable of learning, adaptation, and intuitive insight. Large Language Models (LLMs) have proven their ability, given the proper memories or context, to reason and respond meaningfully to stimuli. However, they are still unable to optimally encode, store, and retrieve memories - the ability to do this would unlock their full ability to operate as AI agents, and to specialize to niche domains. To remedy this, one promising area of research is Retrieval Augmented Generation (RAG), which aims to augment LLMs by providing them with rich in-context examples and information. In question-answering (QA) applications, RAG methods embed the text of interest in chunks, and retrieve the most relevant chunks for a prompt using text embeddings. Motivated by human memory encoding and retrieval, we aim to improve over standard RAG methods by generating and encoding higher-level information and tagging the chunks by their utility to answer questions. We introduce Graphical Eigen Memories For Retrieval Augmented Generation (GEM-RAG). GEM-RAG works by tagging each chunk of text in a given text corpus with LLM generated __tility_ questions, connecting chunks in a graph based on the similarity of both their text and utility questions, and then using the eigendecomposition of the memory graph to build higher level summary nodes that capture the main themes of the text. As a result, GEM-RAG not only provides a more principled method for RAG tasks, but also synthesizes graphical eigen memory (GEM) which can be useful for both exploring text and understanding which components are relevant to a given question. We evaluate GEM-RAG, using both UnifiedQA and GPT-3.5 Turbo as the LLMs, with SBERT, and OpenAI__ text encoders on two standard QA tasks, showing that GEM-RAG outperforms other state-of-the-art RAG methods on these tasks. We also discuss the implications of having a robust RAG system and future directions."
"Controlling Risk of Retrieval-augmented Generation: A Counterfactual
 Prompting Framework",https://arxiv.org/pdf/2409.16146,"Lu Chen, Ruqing Zhang, Jiafeng Guo, Yixing Fan, Xueqi Cheng",2024-09-24T14:52:14Z,Other,Lu Chen,83,Ruqing Zhang,18,"Retrieval-augmented generation (RAG) has emerged as a popular solution to mitigate the hallucination issues of large language models. However, existing studies on RAG seldom address the issue of predictive uncertainty, i.e., how likely it is that a RAG model__ prediction is incorrect, resulting in uncontrollable risks in real-world applications. In this work, we emphasize the importance of risk control, ensuring that RAG models proactively refuse to answer questions with low confidence. Our research identifies two critical latent factors affecting RAG__ confidence in its predictions: the quality of the retrieved results and the manner in which these results are utilized. To guide RAG models in assessing their own confidence based on these two latent factors, we develop a counterfactual prompting framework that induces the models to alter these factors and analyzes the effect on their answers. We also introduce a benchmarking procedure to collect answers with the option to abstain, facilitating a series of experiments. For evaluation, we introduce several risk-related metrics and the experimental results demonstrate the effectiveness of our approach. Our code and benchmark dataset are available at https://github.com/ictbigdatalab/RC-RAG."
Corpus-informed Retrieval Augmented Generation of Clarifying Questions,https://arxiv.org/pdf/2409.18575,"Antonios Minas Krasakis, Andrew Yates, Evangelos Kanoulas",2024-09-27T09:20:42Z,Retrieval Augmented Generation,"Antonios Minas Krasakis, Andrew Yates",3,Andrew Yates,NA,"This study aims to develop models that generate corpus informed clarifying questions for web search, in a way that ensures the questions align with the available information in the retrieval corpus. We demonstrate the effectiveness of Retrieval Augmented Language Models (RAG) in this process, emphasising their ability to (i) jointly model the user query and retrieval corpus to pinpoint the uncertainty and ask for clarifications end-to-end and (ii) model more evidence documents, which can be used towards increasing the breadth of the questions asked. However, we observe that in current datasets search intents are largely unsupported by the corpus, which is problematic both for training and evaluation. This causes question generation models to __allucinate_, ie. suggest intents that are not in the corpus, which can have detrimental effects in performance. To address this, we propose dataset augmentation methods that align the ground truth clarifications with the retrieval corpus. Additionally, we explore techniques to enhance the relevance of the evidence pool during inference, but find that identifying ground truth intents within the corpus remains challenging. Our analysis suggests that this challenge is partly due to the bias of current datasets towards clarification taxonomies and calls for data that can support generating corpus-informed clarifications."
AdvSecureNet: A Python Toolkit for Adversarial Machine Learning,https://arxiv.org/pdf/2409.02629,"Melih Catal, Manuel G_nther",2024-09-04T11:47:00Z,Adversarial Machine Learning,Melih Catal,NA,Manuel G_nther,29,"Machine learning models are vulnerable to adversarial attacks. Several tools have been developed to research these vulnerabilities, but they often lack comprehensive features and flexibility. We introduce AdvSecureNet, a PyTorch based toolkit for adversarial machine learning that is the first to natively support multi-GPU setups for attacks, defenses, and evaluation. It is the first toolkit that supports both CLI and API interfaces and external YAML configuration files to enhance versatility and reproducibility. The toolkit includes multiple attacks, defenses and evaluation metrics. Rigiorous software engineering practices are followed to ensure high code quality and maintainability. The project is available as an open-source project on GitHub at https://github.com/melihcatal/advsecurenet and installable via PyPI. Keywords: Adversarial Machine Learning, Trustworthy AI, Research Toolkit, PyTorch"
"Multi-source Stable Variable Importance Measure via Adversarial Machine
 Learning",https://arxiv.org/pdf/2409.07380,"Zitao Wang, Nian Si, Zijian Guo, Molei Liu",2024-09-11T16:13:20Z,Other,Zitao Wang,NA,Nian Si,NA,"As part of enhancing the interpretability of machine learning, it is of renewed interest to quantify and infer the predictive importance of certain exposure covariates. Modern scientific studies often collect data from multiple sources with distributional heterogeneity. Thus, measuring and inferring stable associations across multiple environments is crucial in reliable and generalizable decision-making. In this paper, we propose MIMAL, a novel statistical framework for Multi-source stable Importance Measure via Adversarial Learning. MIMAL measures the importance of some exposure variables by maximizing the worst-case predictive reward over the source mixture. Our framework allows various machine learning methods for confounding adjustment and exposure effect characterization. For inferential analysis, the asymptotic normality of our introduced statistic is established under a general machine learning framework that requires no stronger learning accuracy conditions than those for single source variable importance. Numerical studies with various types of data generation setups and machine learning implementation are conducted to justify the finite-sample performance of MIMAL. We also illustrate our method through a real-world study of Beijing air pollution in multiple locations. Keywords: Nonparametric variable importance; Stable association; Group distributionally robust learning; General machine learning."
"MARAGS: A Multi-Adapter System for Multi-Task Retrieval Augmented
 Generation Question Answering",https://arxiv.org/pdf/2409.03171,Mitchell DeHaven,2024-09-05T01:58:29Z,RAG,Mitchell DeHaven,N/A,NA,NA,"In this paper we present a multi-adapter retrieval augmented generation system (MARAGS) for Meta__ Comprehensive RAG (CRAG) competition for KDD CUP 2024. CRAG is a question answering dataset contains 3 different subtasks aimed at realistic question and answering RAG related tasks, with a diverse set of question topics, question types, time dynamic answers, and questions featuring entities of varying popularity. Our system follows a standard setup for web based RAG, which uses processed web pages to provide context for an LLM to produce generations, while also querying API endpoints for additional information. MARAGS also utilizes multiple different adapters to solve the various requirements for these tasks with a standard cross-encoder model for ranking candidate passages relevant for answering the question. Our system achieved 2nd place for Task 1 as well as 3rd place on Task 2."
"Language Models and Retrieval Augmented Generation for Automated
 Structured Data Extraction from Diagnostic Reports",https://arxiv.org/pdf/2409.10576,"Mohamed Sobhi Jabal, Pranav Warman, Jikai Zhang, Kartikeye Gupta, Ayush Jain, Maciej Mazurowski, Walter Wiggins, Kirti Magudia, Evan Calabrese",2024-09-15T15:21:45Z,Retrieval Augmented Generation,Mohamed Sobhi Jabal,9,Pranav Warman,8,"Purpose: To develop and evaluate an automated system for extracting structured clinical information from unstructured radiology and pathology reports using open-weights large language models (LMs) and retrieval augmented generation (RAG), and to assess the effects of model configuration variables on extraction performance. Methods and Materials: The study utilized two datasets: 7,294 radiology reports annotated for Brain Tumor Reporting and Data System (BT-RADS) scores and 2,154 pathology reports annotated for isocitrate dehydrogenase (IDH) mutation status. An automated pipeline was developed to benchmark the performance of various LMs and RAG configurations. The impact of model size, quantization, prompting strategies, output formatting, and inference parameters was systematically evaluated. Results: The best performing models achieved over 98% accuracy in extracting BT-RADS scores from radiology reports and over 90% for IDH mutation status extraction from pathology reports. The top model being medical fine-tuned llama3. Larger, newer, and domain fine-tuned models consistently outperformed older and smaller models. Model quantization had minimal impact on performance. Few-shot prompting significantly improved accuracy. RAG improved performance for complex pathology reports but not for shorter radiology reports. Conclusions: Open LMs demonstrate significant potential for automated extraction of structured clinical data from unstructured clinical reports with local privacy-preserving application. Careful model selection, prompt engineering, and semi-automated optimization using annotated data are critical for optimal performance. These approaches could be reliable enough for practical use in research workflows, highlighting the potential for human-machine collaboration in healthcare data extraction."
"P-RAG: Progressive Retrieval Augmented Generation For Planning on
 Embodied Everyday Task",https://arxiv.org/pdf/2409.11279,"Weiye Xu, Min Wang, Wengang Zhou, Houqiang Li",2024-09-17T15:29:34Z,"Retrieval Augmented Generation, RAG",Weiye Xu,3,Min Wang,97,"Embodied Everyday Task is a popular task in the embodied AI community, requiring agents to make a sequence of actions based on natural language instructions and visual observations. Traditional learning-based approaches face two challenges. Firstly, natural language instructions often lack explicit task planning. Secondly, extensive training is required to equip models with knowledge of the task environment. Previous works based on Large Language Model (LLM) either suffer from poor performance due to the lack of taskspecific knowledge or rely on ground truth as few-shot samples. To address the above limitations, we propose a novel approach called Progressive Retrieval Augmented Generation (P-RAG), which not only effectively leverages the powerful language processing capabilities of LLMs but also progressively accumulates task-specific knowledge without ground-truth. Compared to the conventional RAG methods, which retrieve relevant information from the database in a one-shot manner to assist generation, P-RAG introduces an iterative approach to progressively update the database. In each iteration, P-RAG retrieves the latest database and obtains historical information from the previous interaction as experiential references for the current interaction. Moreover, we also introduce a more granular retrieval scheme that not only retrieves similar tasks but also incorporates retrieval of similar situations to provide more valuable reference experiences. Extensive experiments reveal that P-RAG achieves competitive results without utilizing ground truth and can even further improve performance through self-iterations."
"Enhancing E-commerce Product Title Translation with Retrieval-Augmented
 Generation and Large Language Models",https://arxiv.org/pdf/2409.12880,"Bryan Zhang, Taichi Nakatani, Stephan Walter",2024-09-19T16:23:42Z,Other,Bryan Zhang,4,Taichi Nakatani,1,"E-commerce stores enable multilingual product discovery which require accurate product title translation. Multilingual large language models (LLMs) have shown promising capacity to perform machine translation tasks, and it can also enhance and translate product titles cross-lingually in one step. However, product title translation often requires more than just language conversion because titles are short, lack context, and contain specialized terminology. This study proposes a retrieval-augmented generation (RAG) approach that leverages existing bilingual product information in e-commerce by retrieving similar bilingual examples and incorporating them as few-shot prompts to enhance LLM-based product title translation. Experiment results show that our proposed RAG approach improve product title translation quality with chrF score gains of up to 15.3% for language pairs where the LLM has limited proficiency"
"Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented
 Generation",https://arxiv.org/pdf/2409.12941,"Satyapriya Krishna, Kalpesh Krishna, Anhad Mohananey, Steven Schwarcz, Adam Stambler, Shyam Upadhyay, Manaal Faruqui",2024-09-19T17:52:07Z,Other,Satyapriya Krishna,12,Kalpesh Krishna,19,"Large Language Models (LLMs) have demonstrated significant performance improvements across various cognitive tasks. An emerging application is using LLMs to enhance retrieval-augmented generation (RAG) capabilities. These systems require LLMs to understand user queries, retrieve relevant information, and synthesize coherent and accurate responses. Given the increasing real-world deployment of such systems, comprehensive evaluation becomes crucial. To this end, we propose FRAMES (Factuality, Retrieval, And reasoning MEasurement Set), a high-quality evaluation dataset designed to test LLMs_ ability to provide factual responses, assess retrieval capabilities, and evaluate the reasoning required to generate final answers. While previous work has provided datasets and benchmarks to evaluate these abilities in isolation, FRAMES offers a unified framework that provides a clearer picture of LLM performance in end-to-end RAG scenarios. Our dataset comprises challenging multi-hop questions that require the integration of information from multiple sources. We present baseline results demonstrating that even state-of-the-art LLMs struggle with this task, achieving 0.40 accuracy with no retrieval. The accuracy is significantly improved with our proposed multi-step retrieval pipeline, achieving an accuracy of 0.66 (>50% improvement). We hope our work will help bridge evaluation gaps and assist in developing more robust and capable RAG systems."
"RepoGenReflex: Enhancing Repository-Level Code Completion with Verbal
 Reinforcement and Retrieval-Augmented Generation",https://arxiv.org/pdf/2409.13122,"Jicheng Wang, Yifeng He, Hao Chen",2024-09-19T23:38:59Z,Other,Jicheng Wang,25,Yifeng He,2,"In real-world software engineering tasks, solving a problem often requires understanding and modifying multiple functions, classes, and files across a large codebase. Therefore, on the repository level, it is crucial to extract the relevant information to achieve accurate code completion effectively. Existing code completion tools have achieved some success, but they struggle to optimize the retrieval and generation process dynamically. In this paper, we propose RepoGenReflex, a generic, dynamic, effective framework to address this challenge. By leveraging the Retrieval-Augmented Generation (RAG) enhanced with Verbal Reinforcement Learning (VRL), it can dynamically choose the optimal results for repository-level code completion. RepoGenReflex uses Reflector to give directional feedback to the next loop. RepoGenReflex chooses the optimal results stored in the Experience cache based on the RAG-VRL loop. To validate the framework__ generalization ability, we propose a new benchmark RepoGenEval, which consists of the latest, high-quality real-world repositories in line completion scenarios. Our experiments demonstrate that RepoGenReflex achieves significant improvements after optimizing the Reflector component, resulting in enhanced accuracy and relevance of code completions. Additionally, RepoGenReflex consistently demonstrates superior performance and effectiveness across standard code completion tasks, highlighting the robustness and adaptability of our framework. Our source code and benchmark will be publicly available."
"Contextual Compression in Retrieval-Augmented Generation for Large
 Language Models: A Survey",https://arxiv.org/pdf/2409.13385,Sourav Verma,2024-09-20T10:36:49Z,Other,Sourav Verma,8,NA,NA,"Large Language Models (LLMs) showcase remarkable abilities, yet they struggle with limitations such as hallucinations, outdated knowledge, opacity, and inexplicable reasoning. To address these challenges, Retrieval-Augmented Generation (RAG) has proven to be a viable solution, leveraging external databases to improve the consistency and coherence of generated content, especially valuable for complex, knowledge-rich tasks, and facilitates continuous improvement by leveraging domainspecific insights. By combining the intrinsic knowledge of LLMs with the vast, dynamic repositories of external databases, RAG achieves a synergistic effect. However, RAG is not without its limitations, including a limited context window, irrelevant information, and the high processing overhead for extensive contextual data. In this comprehensive work, we explore the evolution of Contextual Compression paradigms, providing an in-depth examination of the field. Finally, we outline the current challenges and suggest potential research and development directions, paving the way for future advancements in this area. 1"
"A Knowledge-Centric Benchmarking Framework and Empirical Study for
 Retrieval-Augmented Generation",https://arxiv.org/pdf/2409.13694,"Shuo Yu, Mingyue Cheng, Jiqian Yang, Jie Ouyang",2024-09-03T03:31:37Z,Other,Shuo Yu,20,Mingyue Cheng,NA,"Retrieval-Augmented Generation (RAG) enhances generative models by integrating retrieval mechanisms, which allow these models to access and utilize external knowledge sources. Despite its advantages, RAG encounters significant challenges, particularly in effectively handling real-world queries and mitigating hallucinations. The KDD Cup 2024 CRAG competition brings these issues to the forefront by incorporating both web pages and a mock API as knowledge sources, adding the complexity of parsing HTML before large language models (LLMs) can process the information. In this paper, we propose a novel RAG benchmark designed to address these challenges. Our work provides a comprehensive set of experimental results, offering valuable insights for the study of RAG. We thoroughly examine the entire RAG process, including knowledge source selection, retrieval, organization, and reasoning. Key findings from our study include the impact of automated knowledge source selection using agents and the influence of noise chunks on RAG reasoning. Additionally, we conduct detailed experiments to analyze the effects of various hyperparameters on RAG performance. To support further research, we have made our results, the associated code, and a parsed version of the CRAG dataset publicly available1 , contributing to the advancement of RAG methodologies and establishing a solid foundation for future work in this domain."
"Retrieval Augmented Generation-Based Incident Resolution Recommendation
 System for IT Support",https://arxiv.org/pdf/2409.13707,"Paulina Toro Isaza, Michael Nidd, Noah Zheutlin, Jae-wook Ahn, Chidansh Amitkumar Bhatt, Yu Deng, Ruchi Mahindru, Martin Franz, Hans Florian, Salim Roukos",2024-09-06T13:06:29Z,Retrieval Augmented Generation,Paulina Toro Isaza,NA,Michael Nidd,12,"Clients wishing to implement generative AI in the domain of IT Support and AIOps face two critical issues: domain coverage and model size constraints due to model choice limitations. Clients might choose to not use larger proprietary models such as GPT-4 due to cost and privacy concerns and so are limited to smaller models with potentially less domain coverage that do not generalize to the client__ domain. Retrieval augmented generation is a common solution that addresses both of these issues: a retrieval system first retrieves the necessary domain knowledge which a smaller generative model leverages as context for generation. We present a system developed for a client in the IT Support domain for support case solution recommendation that combines retrieval augmented generation (RAG) for answer generation with an encoder-only model for classification and a generative large language model for query generation. We cover architecture details, data collection and annotation, development journey and preliminary validations, expected final deployment process and evaluation plans, and finally lessons learned."
"Enhancing Scientific Reproducibility Through Automated BioCompute Object
 Creation Using Retrieval-Augmented Generation from Publications",https://arxiv.org/pdf/2409.15076,"Sean Kim, Raja Mazumder",2024-09-23T14:51:22Z,Other,Sean Kim,10,Raja Mazumder,NA,"The exponential growth in computational power and accessibility has transformed the complexity and scale of bioinformatics research, necessitating standardized documentation for transparency, reproducibility, and regulatory compliance. The IEEE BioCompute Object (BCO) standard addresses this need but faces adoption challenges due to the overhead of creating compliant documentation, especially for legacy research. This paper presents a novel approach to automate the creation of BCOs from scientific papers using Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). We describe the development of the BCO assistant tool that leverages RAG to extract relevant information from source papers and associated code repositories, addressing key challenges such as LLM hallucination and longcontext understanding. The implementation incorporates optimized retrieval processes, including a twopass retrieval with re-ranking, and employs carefully engineered prompts for each BCO domain. We discuss the tool's architecture, extensibility, and evaluation methods, including automated and manual assessment approaches. The BCO assistant demonstrates the potential to significantly reduce the time and effort required for retroactive documentation of bioinformatics research while maintaining compliance with the standard. This approach opens avenues for AI-assisted scientific documentation and knowledge extraction from publications thereby enhancing scientific reproducibility. The BCO assistant tool and documentation is available at https://biocompute-objects.github.io/bco-rag/."
"Lighter And Better: Towards Flexible Context Adaptation For Retrieval
 Augmented Generation",https://arxiv.org/pdf/2409.15699,"Zheng Liu, Chenyuan Wu, Ninglu Shao, Shitao Xiao, Chaozhuo Li, Defu Lian",2024-09-24T03:25:36Z,Other,Zheng Liu,58,Chenyuan Wu,4,"The existing Retrieval-Augmented Generation (RAG) systems face significant challenges in terms of cost and effectiveness. On one hand, they need to encode the lengthy retrieved contexts before responding to the input tasks, which imposes substantial computational overhead. On the other hand, directly using generic Large Language Models (LLMs) often leads to sub-optimal answers, while task-specific fine-tuning may compromise the LLMs_ general capabilities. To address these challenges, we introduce a novel approach called FlexRAG (Flexible Context Adaptation for RAG). In this approach, the retrieved contexts are compressed into compact embeddings before being encoded by the LLMs. Simultaneously, these compressed embeddings are optimized to enhance downstream RAG performance. A key feature of FlexRAG is its flexibility, which enables effective support for diverse compression ratios and selective preservation of important contexts. Thanks to these technical designs, FlexRAG achieves superior generation quality while significantly reducing running costs. Comprehensive experiments on various question-answering datasets validate our approach as a cost-effective and flexible solution for RAG systems."
"AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For
 Asthma Patient Support",https://arxiv.org/pdf/2409.15815,"Adil Bahaj, Mounir Ghogho",2024-09-24T07:24:01Z,Retrieval Augmented Generation,Adil Bahaj,NA,Mounir Ghogho,46,"Asthma rates have risen globally, driven by environmental and lifestyle factors. Access to immediate medical care is limited, particularly in developing countries, necessitating automated support systems. Large Language Models like ChatGPT (Chat Generative Pre-trained Transformer) and Gemini have advanced natural language processing in general and question answering in particular, however, they are prone to producing factually incorrect responses (i.e. hallucinations). Retrievalaugmented generation systems, integrating curated documents, can improve large language models_ performance and reduce the incidence of hallucination. We introduce AsthmaBot, a multi-lingual, multi-modal retrieval-augmented generation system for asthma support. Evaluation of an asthma-related frequently asked questions dataset shows AsthmaBot__ efficacy. AsthmaBot has an added interactive and intuitive interface that integrates different data modalities (text, images, videos) to make it accessible to the larger public. AsthmaBot is available online via asthmabot.datanets.org."
"On the Vulnerability of Applying Retrieval-Augmented Generation within
 Knowledge-Intensive Application Domains",https://arxiv.org/pdf/2409.17275,"Xun Xian, Ganghua Wang, Xuan Bi, Jayanth Srinivasa, Ashish Kundu, Charles Fleming, Mingyi Hong, Jie Ding",2024-09-12T02:43:40Z,Other,Xun Xian,6,Ganghua Wang,14,"Retrieval-Augmented Generation (RAG) has been empirically shown to enhance the performance of large language models (LLMs) in knowledge-intensive domains such as healthcare, finance, and legal contexts. Given a query, RAG retrieves relevant documents from a corpus and integrates them into the LLMs_ generation process. In this study, we investigate the adversarial robustness of RAG, focusing specifically on examining the retrieval system. First, across 225 different setup combinations of corpus, retriever, query, and targeted information, we show that retrieval systems are vulnerable to universal poisoning attacks in medical Q&A. In such attacks, adversaries generate poisoned documents containing a broad spectrum of targeted information, such as personally identifiable information. When these poisoned documents are inserted into a corpus, they can be accurately retrieved by any users, as long as attacker-specified queries are used. To understand this vulnerability, we discovered that the deviation from the query__ embedding to that of the poisoned document tends to follow a pattern in which the high similarity between the poisoned document and the query is retained, thereby enabling precise retrieval. Based on these findings, we develop a new detection-based defense to ensure the safe use of RAG. Through extensive experiments spanning various Q&A domains, we observed that our proposed method consistently achieves excellent detection rates in nearly all cases."
"Enhancing Tourism Recommender Systems for Sustainable City Trips Using
 Retrieval-Augmented Generation",https://arxiv.org/pdf/2409.18003,"Ashmi Banerjee, Adithi Satish, Wolfgang W_rndl",2024-09-26T16:12:33Z,Other,Ashmi Banerjee,4,Adithi Satish,3,"Tourism Recommender Systems (TRS) have traditionally focused on providing personalized travel suggestions, often prioritizing user preferences without considering broader sustainability goals. Integrating sustainability into TRS has become essential with the increasing need to balance environmental impact, local community interests, and visitor satisfaction. This paper proposes a novel approach to enhancing TRS for sustainable city trips using Large Language Models (LLMs) and a modified Retrieval-Augmented Generation (RAG) pipeline. We enhance the traditional RAG system by incorporating a sustainability metric based on a city__ popularity and seasonal demand during the prompt augmentation phase. This modification, called Sustainability Augmented Reranking (SAR), ensures the system__ recommendations align with sustainability goals. Evaluations using popular open-source LLMs, such as Llama-3.1-Instruct-8B and Mistral-Instruct-7B, demonstrate that the SAR-enhanced approach consistently matches or outperforms the baseline (without SAR) across most metrics, highlighting the benefits of incorporating sustainability into TRS. Keywords: Tourism Recommender Systems _ Sustainability _ RetrievalAugmented Generation _ Large Language Models"
"IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through
 Semantic Comprehension in Retrieval-Augmented Generation Scenarios",https://arxiv.org/pdf/2409.15763,"Hai Lin, Shaoxiong Zhan, Junyou Su, Haitao Zheng, Hui Wang",2024-09-24T05:39:53Z,Other,Hai Lin,NA,Shaoxiong Zhan,NA,"In Retrieval-Augmented Generation (RAG) tasks using Large Language Models (LLMs), the quality of retrieved information is critical to the final output. This paper introduces the IRSC benchmark for evaluating the performance of embedding models in multilingual RAG tasks. The benchmark encompasses five retrieval tasks: query retrieval, title retrieval, part-of-paragraph retrieval, keyword retrieval, and summary retrieval. Our research addresses the current lack of comprehensive testing and effective comparison methods for embedding models in RAG scenarios. We introduced new metrics: the Similarity of Semantic Comprehension Index (SSCI) and the Retrieval Capability Contest Index (RCCI), and evaluated models such as Snowflake-Arctic, BGE, GTE, and M3E. Our contributions include: 1) the IRSC benchmark, 2) the SSCI and RCCI metrics, and 3) insights into the cross-lingual limitations of embedding models. The IRSC benchmark aims to enhance the understanding and development of accurate retrieval systems in RAG tasks. All code and datasets are available at: https://github.com/Jasaxion/IRSC_Benchmark"
The Role of Explainable AI in Revolutionizing Human Health Monitoring,https://arxiv.org/pdf/2409.07347,"Abdullah Alharthi, Ahmed Alqurashi, Turki Alharbi, Mohammed Alammar, Nasser Aldosari, Houssem Bouchekara, Yusuf Shaaban, Mohammad Shoaib Shahriar, Abdulrahman Al Ayidh",2024-09-11T15:31:40Z,Explainable AI,Abdullah Alharthi,7,Ahmed Alqurashi,NA,"The complex nature of disease mechanisms and the variability of patient symptoms present significant obstacles in developing effective diagnostic tools. Although machine learning has made considerable advances in medical diagnosis, its decision-making processes frequently lack transparency, which can jeopardize patient outcomes. This underscores the critical need for Explainable AI (XAI), which not only offers greater clarity but also has the potential to significantly improve patient care. In this literature review, we conduct a detailed analysis of analyzing XAI methods identified through searches across various databases, focusing on chronic conditions such as Parkinson's, stroke, depression, cancer, heart disease, and Alzheimer's disease. The literature search revealed the application of 9 trending XAI algorithms in the field of healthcare and highlighted the pros and cons of each of them. Thus, the article is concluded with a critical appraisal of the challenges and future research opportunities for XAI in human health monitoring."
Explainable AI needs formal notions of explanation correctness,https://arxiv.org/pdf/2409.14590,"Stefan Haufe, Rick Wilming, Benedict Clark, Rustam Zhumagambetov, Danny Panknin, Ahc_ne Boubekki",2024-09-22T20:47:04Z,Explainable AI,Stefan Haufe,37,Rick Wilming,4,"The use of machine learning (ML) in critical domains such as medicine poses risks and requires regulation. One requirement is that decisions of ML systems in high-risk applications should be human-understandable. The field of __xplainable artificial intelligence_ (XAI) seemingly addresses this need. However, in its current form, XAI is unfit to provide quality control for ML; it itself needs scrutiny. Popular XAI methods cannot reliably answer important questions about ML models, their training data, or a given test input. We recapitulate results demonstrating that popular XAI methods systematically attribute importance to input features that are independent of the prediction target. This limits their utility for purposes such as model and data (in)validation, model improvement, and scientific discovery. We argue that the fundamental reason for this limitation is that current XAI methods do not address well-defined problems and are not evaluated against objective criteria of explanation correctness. Researchers should formally define the problems they intend to solve first and then design methods accordingly. This will lead to notions of explanation correctness that can be theoretically verified and objective metrics of explanation performance that can be assessed using ground-truth data."
"Enhancing Large Language Models with Domain-specific Retrieval Augment
 Generation: A Case Study on Long-form Consumer Health Question Answering in
 Ophthalmology",https://arxiv.org/pdf/2409.13902,"Aidan Gilson, Xuguang Ai, Thilaka Arunachalam, Ziyou Chen, Ki Xiong Cheong, Amisha Dave, Cameron Duic, Mercy Kibe, Annette Kaminaka, Minali Prasad, Fares Siddig, Maxwell Singer, Wendy Wong, Qiao Jin, Tiarnan D. L. Keenan, Xia Hu, Emily Y. Chew, Zhiyong Lu, Hua Xu, Ron A. Adelman, Yih-Chung Tham, Qingyu Chen",2024-09-20T21:06:00Z,Other,Aidan Gilson,3,Xuguang Ai,2,"Despite the potential of Large Language Models (LLMs) in medicine, they may generate responses lacking supporting evidence or based on hallucinated evidence. While Retrieval Augment Generation (RAG) is popular to address this issue, few studies implemented and evaluated RAG in downstream domain-specific applications. We developed a RAG pipeline with ~70,000 ophthalmology-specific documents that retrieve relevant documents to augment LLMs during inference time. In a case study on long-form consumer health questions, we systematically evaluated the responses _ including over 500 references _ of LLMs with and without RAG on 100 questions with 10 healthcare professionals. The evaluation focuses on factuality of evidence, selection and ranking of evidence, attribution of evidence, and answer accuracy and completeness. LLMs without RAG provided 252 references in total. Of which, 45.3% hallucinated, 34.1% consisted of minor errors, and 20.6% were correct. In contrast, LLMs with RAG significantly improved accuracy (54.5% being correct) and reduced error rates (18.8% with minor hallucinations and 26.7% with errors). 62.5% of the top 10 documents retrieved by RAG were selected as the top references in the LLM response, with an average ranking of 4.9. The use of RAG also improved evidence attribution (increasing from 1.85 to 2.49 on a 5-point scale, P<0.001), albeit with slight decreases in accuracy (from 3.52 to 3.23, P=0.03) and completeness (from 3.47 to 3.27, P=0.17). The results demonstrate that LLMs frequently exhibited hallucinated and erroneous evidence in the responses, raising concerns for downstream applications in the medical domain. RAG substantially reduced the proportion of such evidence but encountered challenges. In contrast to existing studies, the results highlight that (1) LLMs may not select top-ranked documents by RAG, which results in hallucinated evidence remaining, (2) LLMs may miss top-ranked documents by RAG, and (3) irrelevant documents by RAG downgrade response accuracy and completeness, especially in challenging tasks such as long-form question answering. In conclusion, in long-form medical question answering, the RAG approach demonstrated improved effectiveness over non-RAG approach. Nevertheless, there are still challenges in evidence retrieval, selection, and attribution, highlighting the need for further development in domain-specific LLM and RAG techniques."
"AI Assistants for Spaceflight Procedures: Combining Generative
 Pre-Trained Transformer and Retrieval-Augmented Generation on Knowledge
 Graphs With Augmented Reality Cues",https://arxiv.org/pdf/2409.14206,"Oliver Bensch, Leonie Bensch, Tommy Nilsson, Florian Saling, Bernd Bewer, Sophie Jentzsch, Tobias Hecking, J. Nathan Kutz",2024-09-21T17:41:46Z,Other,Oliver Bensch,2,Leonie Bensch,5,"This paper describes the capabilities and potential of the intelligent personal assistant (IPA) CORE (Checklist Organizer for Research and Exploration), designed to support astronauts during procedures onboard the International Space Station (ISS), the Lunar Gateway station, and beyond. We reflect on the importance of a reliable and flexible assistant capable of offline operation and highlight the usefulness of audiovisual interaction using augmented reality elements to intuitively display checklist information. We argue that current approaches to the design of IPAs in space operations fall short of meeting these criteria. Therefore, we propose CORE as an assistant that combines Knowledge Graphs (KGs), Retrieval-Augmented Generation (RAG) for a Generative Pre-Trained Transformer (GPT), and Augmented Reality (AR) elements to ensure an intuitive understanding of procedure steps, reliability, offline availability, and flexibility in terms of response style and procedure updates."
"Generative AI Is Not Ready for Clinical Use in Patient Education for
 Lower Back Pain Patients, Even With Retrieval-Augmented Generation",https://arxiv.org/pdf/2409.15260,"Yi-Fei Zhao, Allyn Bove, David Thompson, James Hill, Yi Xu, Yufan Ren, Andrea Hassman, Leming Zhou, Yanshan Wang",2024-09-23T17:56:08Z,Other,Yi-Fei Zhao,NA,Allyn Bove,10,"Low back pain (LBP) is a leading cause of disability globally. Following the onset of LBP and subsequent treatment, adequate patient education is crucial for improving functionality and long-term outcomes. Despite advancements in patient education strategies, significant gaps persist in delivering personalized, evidence-based information to patients with LBP. Recent advancements in large language models (LLMs) and generative artificial intelligence (GenAI) have demonstrated the potential to enhance patient education. However, their application and ef icacy in delivering educational content to patients with LBP remain underexplored and warrant further investigation. In this study, we introduce a novel approach utilizing LLMs with Retrieval-Augmented Generation (RAG) and few-shot learning to generate tailored educational materials for patients with LBP. Physical therapists manually evaluated our model responses for redundancy, accuracy, and completeness using a Likert scale. In addition, the readability of the generated education materials is assessed using the Flesch Reading Ease score. The findings demonstrate that RAG-based LLMs outperform traditional LLMs, providing more accurate, complete, and readable patient education materials with less redundancy. Having said that, our analysis reveals that the generated materials are not yet ready for use in clinical practice. This study underscores the potential of AI-driven models utilizing RAG to improve patient education for LBP; however, significant challenges remain in ensuring the clinical relevance and granularity of content generated by these models."
ValueCompass: A Framework of Fundamental Values for Human-AI Alignment,https://arxiv.org/pdf/2409.09586,"Hua Shen, Tiffany Knearem, Reshmi Ghosh, Yu-Ju Yang, Tanushree Mitra, Yun Huang",2024-09-15T02:13:03Z,AI Alignment,Hua Shen,11,Tiffany Knearem,7,"As AI systems become more advanced, ensuring their alignment with a diverse range of individuals and societal values becomes increasingly critical. But how can we capture fundamental human values and assess the degree to which AI systems align with them? We introduce ValueCompass, a framework of fundamental values, grounded in psychological theory and a systematic review, to identify and evaluate human-AI alignment. We apply ValueCompass to measure the value alignment of humans and language models (LMs) across four real-world vignettes: collaborative writing, education, public sectors, and healthcare. Our findings reveal significant misalignments between humans and LMs, such as LMs endorsing values like __hoose Own Goals_, which are largely disagreed by humans. We also observe that values differ across vignettes, highlighting the need for context-aware AI alignment strategies. This work provides valuable insights into the design space of human-AI alignment, laying the foundations for developing AI systems that responsibly reflect societal values and ethics."
State-free Reinforcement Learning,https://arxiv.org/pdf/2409.18439,"Mingyu Chen, Aldo Pacchiano, Xuezhou Zhang",2024-09-27T04:28:19Z,Reinforcement Learning,Mingyu Chen,2,Aldo Pacchiano,25,"In this work, we study the state-free RL problem, where the algorithm does not have the states information before interacting with the environment. Specifically, denote the reachable state set by S _ := {s| max___ q P,_(s) > 0}, we design an algorithm which requires no information on the state space S while having a regret that is completely independent of S and only depend on S _. We view this as a concrete first step towards parameter-free RL, with the goal of designing RL algorithms that require no hyper-parameter tuning."
Block-Attention for Efficient RAG,https://arxiv.org/pdf/2409.15355,"East Sun, Yan Wang, Lan Tian",2024-09-14T02:34:26Z,RAG,East Sun,NA,Yan Wang,67,"We introduce Block-Attention, an attention mechanism designed to address the increased inference latency and cost in Retrieval-Augmented Generation (RAG) scenarios. Traditional approaches often encode the entire context. Instead, BlockAttention divides retrieved documents into discrete blocks, with each block independently calculating key-value (KV) states except for the final block. In RAG scenarios, by defining each passage as a block, Block-Attention enables us to reuse the KV states of passages that have been seen before, thereby significantly reducing the latency and the computation overhead during inference. The implementation of Block-Attention involves block segmentation, position re-encoding, and fine-tuning the LLM to adapt to the Block-Attention mechanism. Experiments on four RAG benchmarks demonstrate that after block fine-tuning, the Block-Attention model achieves performance comparable to self-attention models (68.4% vs 67.9% on Llama3) or even superior performance (62.8% vs 59.6% on Mistral). Notably, Block-Attention significantly reduces the time to first token (TTFT) and floating point operations (FLOPs) to a very low level. It only takes 45 ms to output the first token for an input sequence with a total length of 32K. Compared to the self-attention models, the time consumption and corresponding FLOPs are reduced by 98.7% and 99.8%, respectively"
"Explainable AI for computational pathology identifies model limitations
 and tissue biomarkers",https://arxiv.org/pdf/2409.03080,"Jakub R. Kaczmarzyk, Joel H. Saltz, Peter K. Koo",2024-09-04T21:08:55Z,Explainable AI,Jakub R. Kaczmarzyk,13,Joel H. Saltz,86,"Deep learning models have shown promise in histopathology image analysis, but their opaque decision-making process poses challenges in high-risk medical scenarios. Here we introduce HIPPO, an explainable AI method that interrogates attention-based multiple instance learning (ABMIL) models in computational pathology by generating counterfactual examples through tissue patch modifications in whole slide images. Applying HIPPO to ABMIL models trained to detect breast cancer metastasis reveals that they may overlook small tumors and can be misled by non-tumor tissue, while attention maps__idely used for interpretation__ften highlight regions that do not directly influence predictions. By interpreting ABMIL models trained on a prognostic prediction task, HIPPO identified tissue areas with stronger prognostic effects than high-attention regions, which sometimes showed counterintuitive influences on risk scores. These findings demonstrate HIPPO__ capacity for comprehensive model evaluation, bias detection, and quantitative hypothesis testing. HIPPO greatly expands the capabilities of explainable AI tools to assess the trustworthy and reliable development, deployment, and regulation of weakly-supervised models in computational pathology."
"Towards Interpretable End-Stage Renal Disease (ESRD) Prediction:
 Utilizing Administrative Claims Data with Explainable AI Techniques",https://arxiv.org/pdf/2409.12087,"Yubo Li, Saba Al-Sayouri, Rema Padman",2024-09-18T16:03:57Z,Explainable AI,Yubo Li,NA,Saba Al-Sayouri,NA,"This study explores the potential of utilizing administrative claims data, combined with advanced machine learning and deep learning techniques, to predict the progression of Chronic Kidney Disease (CKD) to End-Stage Renal Disease (ESRD). We analyze a comprehensive, 10-year dataset provided by a major health insurance organization to develop prediction models for multiple observation windows using traditional machine learning methods such as Random Forest and XGBoost as well as deep learning approaches such as Long Short-Term Memory (LSTM) networks. Our findings demonstrate that the LSTM model, particularly with a 24-month observation window, exhibits superior performance in predicting ESRD progression, outperforming existing models in the literature. We further apply SHapley Additive exPlanations (SHAP) analysis to enhance interpretability, providing insights into the impact of individual features on predictions at the individual patient level. This study underscores the value of leveraging administrative claims data for CKD management and predicting ESRD progression."
"An Adaptive End-to-End IoT Security Framework Using Explainable AI and
 LLMs",https://arxiv.org/pdf/2409.13177,"Sudipto Baral, Sajal Saha, Anwar Haque",2024-09-20T03:09:23Z,Explainable AI,Sudipto Baral,NA,Sajal Saha,9,"The exponential growth of the Internet of Things (IoT) has significantly increased the complexity and volume of cybersecurity threats, necessitating the development of advanced, scalable, and interpretable security frameworks. This paper presents an innovative, comprehensive framework for real-time IoT attack detection and response that leverages Machine Learning (ML), Explainable AI (XAI), and Large Language Models (LLM). By integrating XAI techniques such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Modelagnostic Explanations) with a model-independent architecture, we ensure our framework__ adaptability across various ML algorithms. Additionally, the incorporation of LLMs enhances the interpretability and accessibility of detection decisions, providing system administrators with actionable, human-understandable explanations of detected threats. Our end-to-end framework not only facilitates a seamless transition from model development to deployment but also represents a real-world application capability that is often lacking in existing research. Based on our experiments with the CIC-IOT-2023 dataset [1], Gemini and OPENAI LLMS demonstrate unique strengths in attack mitigation: Gemini offers precise, focused strategies, while OPENAI provides extensive, in-depth security measures. Incorporating SHAP and LIME algorithms within XAI provides comprehensive insights into attack detection, emphasizing opportunities for model improvement through detailed feature analysis, finetuning, and the adaptation of misclassifications to enhance accuracy."
"Dermatologist-like explainable AI enhances melanoma diagnosis accuracy:
 eye-tracking study",https://arxiv.org/pdf/2409.13476,"Tirtha Chanda, Sarah Haggenmueller, Tabea-Clara Bucher, Tim Holland-Letz, Harald Kittler, Philipp Tschandl, Markus V. Heppt, Carola Berking, Jochen S. Utikal, Bastian Schilling, Claudia Buerger, Cristian Navarrete-Dechent, Matthias Goebeler, Jakob Nikolas Kather, Carolin V. Schneider, Benjamin Durani, Hendrike Durani, Martin Jansen, Juliane Wacker, Joerg Wacker, Reader Study Consortium, Titus J. Brinker",2024-09-20T13:08:33Z,Explainable AI,Tirtha Chanda ,20,Sarah Haggenmueller,1,"Artificial intelligence (AI) systems have substantially improved dermatologists' diagnostic accuracy for melanoma, with explainable AI (XAI) systems further enhancing clinicians' confidence and trust in AI-driven decisions. Despite these advancements, there remains a critical need for objective evaluation of how dermatologists engage with both AI and XAI tools. In this study, 76 dermatologists participated in a reader study, diagnosing 16 dermoscopic images of melanomas and nevi using an XAI system that provides detailed, domain-specific explanations. Eye-tracking technology was employed to assess their interactions. Diagnostic performance was compared with that of a standard AI system lacking explanatory features. Our findings reveal that XAI systems improved balanced diagnostic accuracy by 2.8 percentage points relative to standard AI. Moreover, diagnostic disagreements with AI/XAI systems and complex lesions were associated with elevated cognitive load, as evidenced by increased ocular fixations. These insights have significant implications for clinical practice, the design of AI tools for visual tasks, and the broader development of XAI in medical diagnostics."
"Explainable AI: Definition and attributes of a good explanation for
 health AI",https://arxiv.org/pdf/2409.15338,"Evangelia Kyrimi, Scott McLachlan, Jared M Wohlgemut, Zane B Perkins, David A. Lagnado, William Marsh, the ExAIDSS Expert Group",2024-09-09T16:56:31Z,Explainable AI,Evangelia Kyrimi,14,Scott McLachlan,19,"Proposals of artificial intelligence (AI) solutions based on increasingly complex and accurate predictive models are becoming ubiquitous across many disciplines. As the complexity of these models grows, transparency and users_ understanding often diminish. This suggests that accurate prediction alone is insufficient for making an AI-based solution truly useful. In the development of healthcare systems, this introduces new issues related to accountability and safety. Understanding how and why an AI system makes a recommendation may require complex explanations of its inner workings and reasoning processes. Although research on explainable AI (XAI) has significantly increased in recent years and there is high demand for XAI in medicine, defining what constitutes a good explanation remains ad hoc, and providing adequate explanations continues to be challenging. To fully realize the potential of AI, it is critical to address two fundamental questions about explanations for safety-critical AI applications, such as health-AI: (1) What is an explanation in health-AI? and (2) What are the attributes of a good explanation in health-AI? In this study, we examined published literature and gathered expert opinions through a two-round Delphi study. The research outputs include (1) a definition of what constitutes an explanation in health-AI and (2) a comprehensive list of attributes that characterize a good explanation in health-AI."
"Explainable AI for Autism Diagnosis: Identifying Critical Brain Regions
 Using fMRI Data",https://arxiv.org/pdf/2409.15374,"Suryansh Vidya, Kush Gupta, Amir Aly, Andy Wills, Emmanuel Ifeachor, Rohit Shankar",2024-09-19T23:08:09Z,Explainable AI,Suryansh Vidya,58,Kush Gupta,9,"Early diagnosis and intervention for Autism Spectrum Disorder (ASD) has been shown to significantly improve the quality of life of autistic individuals. However, diagnostics methods for ASD rely on assessments based on clinical presentation that are prone to bias and can be challenging to arrive at an early diagnosis. There is a need for objective biomarkers of ASD which can help improve diagnostic accuracy. Deep learning (DL) has achieved outstanding performance in diagnosing diseases and conditions from medical imaging data. Extensive research has been conducted on creating models that classify ASD using resting-state functional Magnetic Resonance Imaging (fMRI) data. However, existing models lack interpretability. This research aims to improve the accuracy and interpretability of ASD diagnosis by creating a DL model that can not only accurately classify ASD but also provide explainable insights into its working. The dataset used is a preprocessed version of the Autism Brain Imaging Data Exchange (ABIDE) with 884 samples. Our findings show a model that can accurately classify ASD and highlight critical brain regions differing between ASD and typical controls, with potential implications for early diagnosis and understanding of the neural basis of ASD. These findings are validated by studies in the literature that use different datasets and modalities, confirming that the model actually learned characteristics of ASD and not just the dataset. This study advances the field of explainable AI in medical imaging by providing a robust and interpretable model, thereby contributing to a future with objective and reliable ASD diagnostics."
"Navigating the Maze of Explainable AI: A Systematic Approach to
 Evaluating Methods and Metrics",https://arxiv.org/pdf/2409.16756,"Lukas Klein, Carsten T. L_th, Udo Schlegel, Till J. Bungert, Mennatallah El-Assady, Paul F. J_ger",2024-09-25T09:07:46Z,Explainable AI,Lukas Klein,3,Carsten T. L_th,5,"Explainable AI (XAI) is a rapidly growing domain with a myriad of proposed methods as well as metrics aiming to evaluate their efficacy. However, current studies are often of limited scope, examining only a handful of XAI methods and ignoring underlying design parameters for performance, such as the model architecture or the nature of input data. Moreover, they often rely on one or a few metrics and neglect thorough validation, increasing the risk of selection bias and ignoring discrepancies among metrics. These shortcomings leave practitioners confused about which method to choose for their problem. In response, we introduce LATEC, a large-scale benchmark that critically evaluates 17 prominent XAI methods using 20 distinct metrics. We systematically incorporate vital design parameters like varied architectures and diverse input modalities, resulting in 7,560 examined combinations. Through LATEC, we showcase the high risk of conflicting metrics leading to unreliable rankings and consequently propose a more robust evaluation scheme. Further, we comprehensively evaluate various XAI methods to assist practitioners in selecting appropriate methods aligning with their needs. Curiously, the emerging top-performing method, Expected Gradients, is not examined in any relevant related study. LATEC reinforces its role in future XAI research by publicly releasing all 326k saliency maps and 378k metric scores as a (meta-)evaluation dataset. The benchmark is hosted at: https://github.com/IML-DKFZ/latec."
"Towards User-Focused Research in Training Data Attribution for
 Human-Centered Explainable AI",https://arxiv.org/pdf/2409.16978,"Elisa Nguyen, Johannes Bertram, Evgenii Kortukov, Jean Y. Song, Seong Joon Oh",2024-09-25T14:40:26Z,Explainable AI,Elisa Nguyen,4,Johannes Bertram,NA,"While Explainable AI (XAI) aims to make AI understandable and useful to humans, it has been criticised for relying too much on formalism and solutionism, focusing more on mathematical soundness than user needs. We propose an alternative to this bottom-up approach inspired by design thinking: the XAI research community should adopt a top-down, user-focused perspective to ensure user relevance. We illustrate this with a relatively young subfield of XAI, Training Data Attribution (TDA). With the surge in TDA research and growing competition, the field risks repeating the same patterns of solutionism. We conducted a needfinding study with a diverse group of AI practitioners to identify potential user needs related to TDA. Through interviews (N=10) and a systematic survey (N=31), we uncovered new TDA tasks that are currently largely overlooked. We invite the TDA and XAI communities to consider these novel tasks and improve the user relevance of their research outcomes."
Semifactual Explanations for Reinforcement Learning,https://arxiv.org/pdf/2409.05435,"Jasmina Gajcin, Jovan Jeromela, Ivana Dusparic",2024-09-09T08:37:47Z,Reinforcement Learning,Jasmina Gajcin,4,Jovan Jeromela,2,"Reinforcement Learning (RL) is a learning paradigm in which the agent learns from its environment through trial and error. Deep reinforcement learning (DRL) algorithms represent the agent__ policies using neural networks, making their decisions difficult to interpret. Explaining the behaviour of DRL agents is necessary to advance user trust, increase engagement, and facilitate integration with reallife tasks. Semifactual explanations aim to explain an outcome by providing __ven if_ scenarios, such as __ven if the car were moving twice as slowly, it would still have to swerve to avoid crashing_. Semifactuals help users understand the effects of different factors on the outcome and support the optimisation of resources. While extensively studied in psychology and even utilised in supervised learning, semifactuals have not been used to explain the decisions of RL systems. In this work, we develop a first approach to generating semifactual explanations for RL agents. We start by defining five properties of desirable semifactual explanations in RL and then introducing SGRL-Rewind and SGRL-Advance, the first algorithms for generating semifactual explanations in RL. We evaluate the algorithms in two standard RL environments and find that they generate semifactuals that are easier to reach, represent the agent__ policy better, and are more diverse compared to baselines. Lastly, we conduct and analyse a user study to assess the participant__ perception of semifactual explanations of the agent__ actions."
"Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving
 Human-AI Alignment in the Writing Process through Edits",https://arxiv.org/pdf/2409.14509,"Tuhin Chakrabarty, Philippe Laban, Chien-Sheng Wu",2024-09-22T16:13:00Z,AI Alignment,Tuhin Chakrabarty,22,Philippe Laban,16,"LLM-based applications are helping people write, and LLM-generated text is making its way into social media, journalism, and our classrooms. However, the differences between LLM-generated and human-written text remain unclear. To explore this, we hired professional writers to edit paragraphs in several creative domains. We first found these writers agree on undesirable idiosyncrasies in LLM-generated text, formalizing it into a seven-category taxonomy (e.g. clich_s, unnecessary exposition). Second, we curated the LAMP corpus: 1,057 LLM-generated paragraphs edited by professional writers according to our taxonomy. Analysis of LAMP reveals that none of the LLMs used in our study (GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) outperform each other in terms of writing quality, revealing common limitations across model families. Third, we explored automatic editing methods to improve LLM-generated text. A large-scale preference annotation confirms that although experts largely prefer text edited by other experts, automatic editing methods show promise in improving alignment between LLM-generated and human-written text. CCS Concepts: _ Human-centered computing _ Empirical studies in HCI; Empirical studies in collaborative and social computing; _ Computing methodologies _ Natural language generation. Additional Key Words and Phrases: Human-AI collaboration, Large Language Models, Design Methods, Text Editing, Natural Language Generation, Evaluation, Writing Assistance, Generative AI, Homogenization, Alignment, Behavioral Science ACM Reference Format: Tuhin Chakrabarty, Philippe Laban, and Chien-Sheng Wu. 2024. Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits. 1, 1 (September 2024), 39 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn"
Crossref,,,,,,,,,
Title,Link,Authors,Publish Date,Topic,,,,,
Fault Classification of 3D-Printing Operations Using Different Types of Machine and Deep Learning Techniques,http://dx.doi.org/10.3390/ai5040087,"Satish Kumar, Sameer Sayyad, Arunkumar Bongale",9/27/2024,Other,Satish Kumar,75,Sameer Sayyad,6,"Fused deposition modeling (FDM), a method of additive manufacturing (AM), comprises the extrusion of materials via a nozzle and the subsequent combining of the layers to create 3D-printed objects. FDM is a widely used method for 3D-printing objects since it is affordable, effective, and easy to use. Some defects such as poor infill, elephant foot, layer shift, and poor surface finish arise in the FDM components at the printing stage due to variations in printing parameters such as printing speed, change in nozzle, or bed temperature. Proper fault classification is required to identify the cause of faulty products. In this work, the multi-sensory data are gathered using different sensors such as vibration, current, temperature, and sound sensors. The data acquisition is performed by using the National Instrumentation (NI) Data Acquisition System (DAQ) which provides the synchronous multi-sensory data for the model training. To induce the faults, the data are captured under different conditions such as variations in printing speed, temperate, and jerk during the printing. The collected data are used to train the machine learning (ML) and deep learning (DL) classification models to classify the variation in printing parameters. The ML models such as k-nearest neighbor (KNN), decision tree (DT), extra trees (ET), and random forest (RF) with convolutional neural network (CNN) as a DL model are used to classify the variable operation printing parameters. Out of the available models, in ML models, the RF classifier shows a classification accuracy of around 91% whereas, in the DL model, the CNN model shows good classification performance with accuracy ranging from 92 to 94% under variable operating conditions."
Software Defect Prediction Based on Machine Learning and Deep Learning Techniques: An Empirical Approach,http://dx.doi.org/10.3390/ai5040086,"Waleed Albattah, Musaad Alzahrani",9/24/2024,Explainable A,Waleed Albattah,20,Musaad Alzahrani,8,"Software bug prediction is a software maintenance technique used to predict the occurrences of bugs in the early stages of the software development process. Early prediction of bugs can reduce the overall cost of software and increase its reliability. Machine learning approaches have recently offered several prediction methods to improve software quality. This paper empirically investigates eight well-known machine learning and deep learning algorithms for software bug prediction. We compare the created models using different evaluation metrics and a well-accepted dataset to make the study results more reliable. This study uses a large dataset collected from five publicly available bug datasets that includes about 60 software metrics. The source-code metrics of internal class quality, including cohesion, coupling, complexity, documentation inheritance, and size metrics, were used as features to predict buggy and non-buggy classes. Four performance metrics, namely accuracy, macro F1 score, weighted F1 score, and binary F1 score, are considered to quantitatively evaluate and compare the performance of the constructed bug prediction models. The results demonstrate that the deep learning model (LSTM) outperforms all other models across these metrics, achieving an accuracy of 0.87."
Beyond model interpretability: socio-structural explanations in machine learning,http://dx.doi.org/10.1007/s00146-024-02056-1,"Andrew Smart, Atoosa Kasirzadeh",9/5/2024,Responsible AI,Andrew Smart,18,Atoosa Kasirzadeh,13,"What is it to interpret the outputs of an opaque machine learning model? One approach is to develop interpretable machine learning techniques. These techniques aim to show how machine learning models function by providing either model-centric local or global explanations, which can be based on mechanistic interpretations (revealing the inner working mechanisms of models) or non-mechanistic approximations (showing input feature__utput data relationships). In this paper, we draw on social philosophy to argue that interpreting machine learning outputs in certain normatively salient domains could require appealing to a third type of explanation that we call __ocio-structural_ explanation. The relevance of this explanation type is motivated by the fact that machine learning models are not isolated entities but are embedded within and shaped by social structures. Socio-structural explanations aim to illustrate how social structures contribute to and partially explain the outputs of machine learning models. We demonstrate the importance of socio-structural explanations by examining a racially biased healthcare allocation algorithm. Our proposal highlights the need for transparency beyond model interpretability: understanding the outputs of machine learning systems could require a broader analysis that extends beyond the understanding of the machine learning model itself."
Leveraging AI and Machine Learning for Predictive Analytics in Business Intelligence,http://dx.doi.org/10.4018/979-8-3693-8844-0.ch002,"Mansi Sharma, Praveen Kumar, Swapnil Gundewar",9/20/2024,Compound AI Systems,Mansi Sharma,5,Praveen Kumar,40,"In today's tech landscape, business intelligence (BI) is essential, especially with advanced technologies emerging. This study delves into the transformative potential of artificial intelligence and machine learning in predictive analytics, offering crucial insights into data. The chapter provides an extensive overview, focusing on the future of predictive analytics in BI. It highlights real-time applications, featuring practical work and case studies. Key practices for integrating AI and predictive analytics are introduced, covering data preparation, cleaning, preprocessing, feature engineering, and exploratory data analysis. Integration of ML with BI facilitates visualization, report generation, interactive dashboards, and real-time monitoring. However, manual analysis of complex datasets poses challenges, risking valuable insights. This chapter explores how ML automates the identification of patterns, extracting insights. Key challenges and advantages in integrating machine learning into BI frameworks are also discussed."
AI and Lifelong Learning in Developing Countries,http://dx.doi.org/10.4018/979-8-3693-0884-4.ch003,"Mohit Yadav, Sandeep Kumar Singh, Parth Sharma, Ta Huy Hung",9/20/2024,Responsible AI,Mohit Yadav,5,Sandeep Kumar Singh,21,"This study explores the role of artificial intelligence (AI) in supporting lifelong learning and development in developing countries, focusing on low-resource contexts. By analyzing case studies of ConveGenius and EkStep in India, and Eneza Education and Geekie in Kenya, the research highlights AI's potential to deliver personalized and adaptive learning experiences. The findings demonstrate significant improvements in educational outcomes and engagement, despite challenges related to digital access, teacher training, and infrastructure. Expert interviews provide additional insights into practical, societal, and theoretical implications, emphasizing the need for sustainable and scalable solutions. This study contributes to understanding AI's transformative impact on education and offers recommendations for enhancing its effectiveness in diverse educational settings."
Development of Lung Cancer Risk Prediction Machine Learning Models for Equitable Learning Health System: Retrospective Study,http://dx.doi.org/10.2196/56590,"Anjun Chen, Erman Wu, Ran Huang, Bairong Shen, Ruobing Han, Jian Wen, Zhiyong Zhang, Qinghua Li",9/11/2024,Responsible AI,Anjun Chen,3,Erman Wu,NA,"Background:
A significant proportion of young at-risk patients and nonsmokers are excluded by the current guidelines for lung cancer (LC) screening, resulting in low-screening adoption. The vision of the US National Academy of Medicine to transform health systems into learning health systems (LHS) holds promise for bringing necessary structural changes to health care, thereby addressing the exclusivity and adoption issues of LC screening.

Objective:
This study aims to realize the LHS vision by designing an equitable, machine learning (ML)__nabled LHS unit for LC screening. It focuses on developing an inclusive and practical LC risk prediction model, suitable for initializing the ML-enabled LHS (ML-LHS) unit. This model aims to empower primary physicians in a clinical research network, linking central hospitals and rural clinics, to routinely deliver risk-based screening for enhancing LC early detection in broader populations.

Methods:
We created a standardized data set of health factors from 1397 patients with LC and 1448 control patients, all aged 30 years and older, including both smokers and nonsmokers, from a hospital__ electronic medical record system. Initially, a data-centric ML approach was used to create inclusive ML models for risk prediction from all available health factors. Subsequently, a quantitative distribution of LC health factors was used in feature engineering to refine the models into a more practical model with fewer variables.

Results:
The initial inclusive 250-variable XGBoost model for LC risk prediction achieved performance metrics of 0.86 recall, 0.90 precision, and 0.89 accuracy. Post feature refinement, a practical 29-variable XGBoost model was developed, displaying performance metrics of 0.80 recall, 0.82 precision, and 0.82 accuracy. This model met the criteria for initializing the ML-LHS unit for risk-based, inclusive LC screening within clinical research networks.

Conclusions:
This study designed an innovative ML-LHS unit for a clinical research network, aiming to sustainably provide inclusive LC screening to all at-risk populations. It developed an inclusive and practical XGBoost model from hospital electronic medical record data, capable of initializing such an ML-LHS unit for community and rural clinics. The anticipated deployment of this ML-LHS unit is expected to significantly improve LC-screening rates and early detection among broader populations, including those typically overlooked by existing screening guidelines.

JMIR AI 2024;3:e56590

doi:10.2196/56590"